{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eg-VsdunT-tW"
   },
   "source": [
    "Do note if running from scratch the following files\\folders must be configured and added to your personal drive or copied by hand.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "1. data folder(zipped) containning trainning, validation and testing folders with tfrecord type files (test files excluded), data folder must include labal_map(see number 3.)\n",
    "2. pipeline.config file into workspace/models/<'your model folder'>/v1/ which can be obtained from the pre-trained model, do note that you must configue and set it up correctly with the correct configurations.\n",
    "3. a labal_map.txt file in the /workspace/data/ folder that will contain class objects you're going to work with.\n",
    "4. copy exporter_main_v2.py and model_main_tf2.py from the downloaded support folder of ./models/research/object_detection/ into /workspace/ folder.\n",
    "\n",
    "the code will run smoothly if data folder is zipped and ready, and the other files are all uploaded to personal drive for the program to grab.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "***Otherwise start from \"unskippable\" part and download the whole workspace from github with everything setup***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skippable part which was the initial setting up for the workspace, skip up untill \"Unskippable\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SJFhY3elhdr3"
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.rmtree('/content/sample_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mB3dldSoDbr2",
    "outputId": "f041931e-daeb-451d-a1a8-ea00e08c941b"
   },
   "outputs": [],
   "source": [
    "!gdown http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dOA4z9lNiEoh"
   },
   "outputs": [],
   "source": [
    "mkdir workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hKKP4jT_iJKn",
    "outputId": "70191ae9-a581-4f60-8158-9c9bde50c5fd"
   },
   "outputs": [],
   "source": [
    "cd workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_IRYdyVqnong"
   },
   "outputs": [],
   "source": [
    "mkdir exported_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ruuozUbnotE4",
    "outputId": "f499e157-89b0-4571-ed61-1a80a77261b3"
   },
   "outputs": [],
   "source": [
    "cd exported_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PC85WjmBoP_0"
   },
   "outputs": [],
   "source": [
    "mkdir ssd_mobilenet_v2_fpnlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nBN4DYJpoxXx",
    "outputId": "eea8f0be-9003-4880-d78f-1f0d03c7c300"
   },
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vySEm8pegsLs"
   },
   "outputs": [],
   "source": [
    "mkdir pre_trained_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "amMCO26gHvd1"
   },
   "outputs": [],
   "source": [
    "mkdir models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aDf-dYJzIH6C",
    "outputId": "fee168b7-0ebb-4ab2-916a-d9f975e1b10e"
   },
   "outputs": [],
   "source": [
    "cd models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TvVMNkkiIP43"
   },
   "outputs": [],
   "source": [
    "mkdir ssd_mobilenet_v2_fpnlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7DDxysc4IRdx",
    "outputId": "60cccdee-9667-4ee8-ebd3-2965de94f75f"
   },
   "outputs": [],
   "source": [
    "cd ssd_mobilenet_v2_fpnlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lz-VHoAVIS6Z"
   },
   "outputs": [],
   "source": [
    "mkdir v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "srbIKEd6VVD-",
    "outputId": "5b03ae1a-ed72-4e91-fa4d-90dcc50f58e3"
   },
   "outputs": [],
   "source": [
    "cd /content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DKdNoY4zDqGS",
    "outputId": "d49d6a00-a850-4f0e-af6a-59a73ef65ecf"
   },
   "outputs": [],
   "source": [
    "#!tar -z ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz\n",
    "!tar -xzvf \"ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz\" -C \"/content/workspace/pre_trained_models\"     #[run this cell to extract tar.gz files]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9-t-0O2eVa19"
   },
   "source": [
    "# Upload data rfrecord files, .py helper scripts and pipeline.config settings we set up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NiWgyAR7lpqK",
    "outputId": "bf917267-d2f3-4876-aa46-536132604582"
   },
   "outputs": [],
   "source": [
    "cd /content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3jkWaFYDeghi",
    "outputId": "418d4abf-3baa-4aba-95e5-cb7e43b757bc"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BzSEnWaQesF9"
   },
   "outputs": [],
   "source": [
    "cp /content/gdrive/MyDrive/data.zip /content/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4ZPkc-3kpC1K"
   },
   "outputs": [],
   "source": [
    "cp /content/gdrive/MyDrive/exporter_main_v2.py /content/workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xE4Uwt07pc0-"
   },
   "outputs": [],
   "source": [
    "cp /content/gdrive/MyDrive/model_main_tf2.py /content/workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hpOsR97epoBB"
   },
   "outputs": [],
   "source": [
    "cp /content/gdrive/MyDrive/pipeline.config /content/workspace/models/ssd_mobilenet_v2_fpnlite/v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GUjbcCqYSj9v",
    "outputId": "347eab4e-1eee-4d1f-aa3b-dbae481f8349"
   },
   "outputs": [],
   "source": [
    "!unzip data.zip -d /content/workspace "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m8qv0-2xDdwl"
   },
   "source": [
    "# We have model we trained before that we're going to use with better configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp /content/gdrive/MyDrive/mode_v1.zip /content/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /content/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip mode_v1.zip -d /content/workspace/models/ssd_mobilenet_v2_fpnlite/v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /content/workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unskippable part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /content/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/Mosa-T/Project_deep_learning.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv /content/Project_deep_learning/workspace /content/ \\\n",
    "mv /content/Project_deep_learning/DL_project_v3.ipynb /content/ \\\n",
    "mv /content/Project_deep_learning/input.mp4 /content/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree('/content/Project_deep_learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "msLr_C_AMxzL",
    "outputId": "197dc738-033d-49ff-fe32-c775daed98a8"
   },
   "outputs": [],
   "source": [
    "!pip install lvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k-35R6ZwPmcF",
    "outputId": "450f912d-aa43-4806-c396-0975fe6d551f"
   },
   "outputs": [],
   "source": [
    "!apt-get install protobuf-compiler python-pil python-lxml python-tk\n",
    "!pip install Cython tf_slim\n",
    "!git clone https://github.com/tensorflow/models.git\n",
    "%cd /content/models/research\n",
    "!protoc object_detection/protos/*.proto --python_out=.\n",
    "%set_env PYTHONPATH=/content/models/research:/content/models/research/slim\n",
    "import os\n",
    "os.environ['PYTHONPATH'] += \":/content/models\"\n",
    "import sys\n",
    "sys.path.append(\"/content/models\")\n",
    "!python object_detection/builders/model_builder_test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vtZSJTMBRSSJ",
    "outputId": "47baa371-ad5a-4dc9-d6bc-2d7f553f1316"
   },
   "outputs": [],
   "source": [
    "pip install tensorflow-addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "resixTnMschi",
    "outputId": "1b35ca2b-5301-4b06-f3bb-0ad6caaab9ee"
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "cores = multiprocessing.cpu_count() # Count the number of cores in a computer\n",
    "cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kN49g3HztAUr"
   },
   "outputs": [],
   "source": [
    "!export CUDA_VISIBLE_DEVICES=0,1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /content/workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fuTixRA3KQ_a",
    "outputId": "d334d30b-0783-4cb3-8d4d-7ffc72acd4e8"
   },
   "outputs": [],
   "source": [
    "!python model_main_tf2.py --pipeline_config_path=/content/workspace/models/ssd_mobilenet_v2_fpnlite/v1/pipeline.config --model_dir=/content/workspace/models/ssd_mobilenet_v2_fpnlite/v1 --checkpoint_every_n=5 --num_workers=2 --alsologtostderr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "73-gIJV7Rq6m"
   },
   "outputs": [],
   "source": [
    "!python exporter_main_v2.py --pipeline_config_path=/content/workspace/models/ssd_mobilenet_v2_fpnlite/v1/pipeline.config --trained_checkpoint_dir=/content/workspace/models/ssd_mobilenet_v2_fpnlite/v1 --output_directory=/content/workspace/exported_models/ssd_mobilenet_v2_fpnlite --input_type=image_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iqCx6qcfKTMc"
   },
   "source": [
    "# Validation model - logs using tensorboard - run locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python model_main_tf2.py --pipeline_config_path=/content/workspace/models/ssd_mobilenet_v2_fpnlite/v1/pipeline.config --model_dir=/content/workspace/models/ssd_mobilenet_v2_fpnlite/v1/ --checkpoint_dir=/content/workspace/models/ssd_mobilenet_v2_fpnlite/v1/ --num_workers=2 --sample_1_of_n_eval_examples=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import datetime, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kill 10460"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir='C:/Users/Mosa-T/Desktop/content/workspace/models/ssd_mobilenet_v2_fpnlite/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard dev upload --logdir 'logs'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MDQrsEaWvJ74"
   },
   "source": [
    "# Testing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q2BVDL-XSj9y"
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow\n",
    "!pip install tqdm\n",
    "!pip install tf_slim\n",
    "!pip install scipy\n",
    "!pip install tf-models-official\n",
    "!pip install pyqt5\n",
    "!pip install mmcv\n",
    "!pip install multiprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hbd4LA65bJxk"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "path2scripts = './models/research/' #provide pass to the research folder\n",
    "sys.path.insert(0, path2scripts) # making scripts in models/research available for import\n",
    "import numpy as np\n",
    "import time\n",
    "import numpy as np\n",
    "import mmcv, cv2\n",
    "from threading import Thread\n",
    "from PIL import Image, ImageDraw\n",
    "from IPython import display\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "import smtplib, ssl\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.image import MIMEImage\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q33tEmFFkbYu",
    "outputId": "99b607e8-9fb2-413e-881b-cdd810af0e10"
   },
   "outputs": [],
   "source": [
    "#tf.config.threading.set_intra_op_parallelism_threads(100)\n",
    "#tf.config.threading.set_inter_op_parallelism_threads(100)\n",
    "if tf.test.gpu_device_name():\n",
    "    print('GPU found')\n",
    "else:\n",
    "    print(\"No GPU found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "biudoAc4krEA"
   },
   "outputs": [],
   "source": [
    "#path2config ='/content/workspace/exported_models/ssd_mobilenet_v2_fpnlite/pipeline.config'\n",
    "#path2model = '/content/workspace/exported_models/ssd_mobilenet_v2_fpnlite/checkpoint'\n",
    "path2config ='C:/Users/Mosa-T/Desktop/content/workspace/exported_models/ssd_mobilenet_v2_fpnlite/pipeline.config'\n",
    "path2model = 'C:/Users/Mosa-T/Desktop/content/workspace/exported_models/ssd_mobilenet_v2_fpnlite/checkpoint'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pv9UXJvRk5d9"
   },
   "outputs": [],
   "source": [
    "configs = config_util.get_configs_from_pipeline_file(path2config) # importing config\n",
    "model_config = configs['model'] # recreating model config\n",
    "detection_model = model_builder.build(model_config=model_config, is_training=False) # importing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K3yJi3rOk7-g",
    "outputId": "cbf7a1f1-7624-4ba7-ddfd-b944a6b0ad89"
   },
   "outputs": [],
   "source": [
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore(os.path.join(path2model, 'ckpt-0')).expect_partial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ekjg1bmIlPXm"
   },
   "outputs": [],
   "source": [
    "path2label_map = 'C:/Users/Mosa-T/Desktop/content/workspace/data/label_map.txt' \n",
    "#path2label_map = '/content/workspace/data/label_map.txt' \n",
    "category_index = label_map_util.create_category_index_from_labelmap(path2label_map,use_display_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qMsqoOTylWrJ"
   },
   "outputs": [],
   "source": [
    "def detect_fn(image):\n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "    return detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def framePred(img):\n",
    "    image_np=img.copy()\n",
    "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "    detections = detect_fn(input_tensor)\n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key: value[0, :num_detections].numpy() for key, value in detections.items()}\n",
    "    detections['num_detections'] = num_detections\n",
    "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "    \n",
    "    label_id_offset = 1\n",
    "    image_np_with_detections = image_np.copy()\n",
    "\n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "            image_np_with_detections,\n",
    "            detections['detection_boxes'],\n",
    "            detections['detection_classes']+label_id_offset,\n",
    "            detections['detection_scores'],\n",
    "            category_index,\n",
    "            use_normalized_coordinates=True,\n",
    "            max_boxes_to_draw=10,\n",
    "            min_score_thresh=0.25,\n",
    "            agnostic_mode=False,\n",
    "            line_thickness=3)\n",
    "    return image_np_with_detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_email_warning(fire_image):\n",
    "    sender_email = \"firedetectionmobilenet@gmail.com\"\n",
    "    receiver_email = \"firedetectionmobilenet@gmail.com\"\n",
    "    #password = input(\"Type your password and press enter:\")\n",
    "    password = ('123qwe!@#qwe')\n",
    "    message = MIMEMultipart(\"alternative\")\n",
    "    message[\"Subject\"] = \"Fire detected!\"\n",
    "    message[\"From\"] = sender_email\n",
    "    message[\"To\"] = receiver_email\n",
    "\n",
    "    # Create the plain-text and HTML version of your message\n",
    "    text = \"\"\"\\\n",
    "    Hi,\n",
    "    We've detected a fire, please check the image to confirm\"\"\"\n",
    "    html = \"\"\"\\\n",
    "    <html>\n",
    "      <body>\n",
    "        <p>Hi,<br>\n",
    "           <br>\n",
    "           We've detected a fire, please check the image to confirm \n",
    "        </p>\n",
    "        <b><br><img src=\"cid:image1\"><br>\n",
    "      </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "\n",
    "    # Turn these into plain/html MIMEText objects\n",
    "    part1 = MIMEText(text, \"plain\")\n",
    "    part2 = MIMEText(html, \"html\")\n",
    "\n",
    "    # Add HTML/plain-text parts to MIMEMultipart message\n",
    "    # The email client will try to render the last part first\n",
    "    message.attach(part1)\n",
    "    message.attach(part2)\n",
    "\n",
    "\n",
    "    #Attach the image\n",
    "    fp = open(fire_image, 'rb')\n",
    "    msgImage = MIMEImage(fp.read())\n",
    "    fp.close()\n",
    "    msgImage.add_header('Content-ID', '<image1>')\n",
    "    message.attach(msgImage)\n",
    "\n",
    "\n",
    "    # Create secure connection with server and send email\n",
    "    context = ssl.create_default_context()\n",
    "    with smtplib.SMTP_SSL(\"smtp.gmail.com\", 465, context=context) as server:\n",
    "        server.login(sender_email, password)\n",
    "        server.sendmail(\n",
    "            sender_email, receiver_email, message.as_string()\n",
    "        )\n",
    "        server.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def framePred_email(img,email_flag):\n",
    "    image_np=img.copy()\n",
    "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "    detections = detect_fn(input_tensor)\n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key: value[0, :num_detections].numpy() for key, value in detections.items()}\n",
    "    detections['num_detections'] = num_detections\n",
    "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "    label_id_offset = 1\n",
    "    image_np_with_detections = image_np.copy()\n",
    "    \n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "            image_np_with_detections,\n",
    "            detections['detection_boxes'],\n",
    "            detections['detection_classes']+label_id_offset,\n",
    "            detections['detection_scores'],\n",
    "            category_index,\n",
    "            use_normalized_coordinates=True,\n",
    "            max_boxes_to_draw=10,\n",
    "            min_score_thresh=0.25,\n",
    "            agnostic_mode=False,\n",
    "            line_thickness=3)\n",
    "    #print(detections['detection_boxes'])\n",
    "    if not email_flag and len(detections['detection_boxes']):\n",
    "        print('fire detected, sending email!')\n",
    "        im = Image.fromarray(image_np_with_detections)\n",
    "        im.save(\"fire_detected.jpg\")\n",
    "        send_email_warning(\"fire_detected.jpg\")\n",
    "        email_flag = True\n",
    "    return image_np_with_detections,email_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2J8xtS4Flbyl"
   },
   "outputs": [],
   "source": [
    "def plot_detection(path2images, box_th=0.25):\n",
    "    for image_path in path2images:\n",
    "\n",
    "        print('Running inference for {}... '.format(image_path), end='')\n",
    "\n",
    "        image_np = np.array(Image.open(image_path))\n",
    "        \n",
    "        input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "        detections = detect_fn(input_tensor)\n",
    "        num_detections = int(detections.pop('num_detections'))\n",
    "        detections = {key: value[0, :num_detections].numpy()\n",
    "                      for key, value in detections.items()}\n",
    "        \n",
    "        detections['num_detections'] = num_detections\n",
    "\n",
    "        detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "        label_id_offset = 1\n",
    "        image_np_with_detections = image_np.copy()\n",
    "\n",
    "        viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "                image_np_with_detections,\n",
    "                detections['detection_boxes'],\n",
    "                detections['detection_classes']+label_id_offset,\n",
    "                detections['detection_scores'],\n",
    "                category_index,\n",
    "                use_normalized_coordinates=True,\n",
    "                max_boxes_to_draw=10,\n",
    "                min_score_thresh=box_th,\n",
    "                agnostic_mode=False,\n",
    "                line_thickness=3)\n",
    "\n",
    "        plt.figure(figsize=(15,10))\n",
    "        plt.imshow(image_np_with_detections)\n",
    "        print('Done')\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 520
    },
    "id": "O5xXtPVkloDi",
    "outputId": "cd485d24-e135-4698-f28d-8d91571f3ca5"
   },
   "outputs": [],
   "source": [
    "plot_detection(['C:/Users/Mosa-T/Desktop/content/workspace/data/test.record/image_39.jpg'])\n",
    "#plot_detection(['/content/workspace/data/test.record/image_39.jpg'])\n",
    "#if it doesn't plot then remove %matlabplot inline, run cell and add it back, run again "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload to train if the results are acceptable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L8wVIINVrej4",
    "outputId": "883abb07-aa01-475d-e51d-3e5b4b845a38"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "\n",
    "#drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C5h6CV6mqFj5"
   },
   "outputs": [],
   "source": [
    "#!zip -r /content/file.zip /content/workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cp /content/file.zip /content/gdrive/MyDrive/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tcrsukFY__Sd"
   },
   "source": [
    "# Main event - Run locally - Colab does a terrible job at playing/displaying videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real time detection - Webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#real time detection\n",
    "cap = cv2.VideoCapture(-1)\n",
    "cap.read()\n",
    "#cap = cv2.VideoCapture('C:/Users/Mosa-T/Desktop/content/workspace/data/test.record/video1.mp4')\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    _,img = cap.read()\n",
    "    detections = framePred(img)\n",
    "    cv2.imshow('object detection',detections)\n",
    "    key=cv2.waitKey(1)\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fire detection of stored videos can be ran on colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#downloaded video fire detection\n",
    "video = mmcv.VideoReader('C:/Users/Mosa-T/Desktop/content/workspace/data/test.record/output.mp4')\n",
    "#video = mmcv.VideoReader('/content/workspace/data/test.record/output.mp4')\n",
    "#frames = [Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)) for frame in video]\n",
    "frames = [(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)) for frame in video]\n",
    "\n",
    "frames_tracked = []\n",
    "for i, frame in enumerate(frames):\n",
    "    print('\\rTracking frames: {}'.format(i + 1), end='')\n",
    "    frame = framePred(frame)\n",
    "    frames_tracked.append(frame)\n",
    "print('\\nDone') \n",
    "#cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save detection video\n",
    "dim = Image.fromarray(frames_tracked[0]).size\n",
    "fourcc = cv2.VideoWriter_fourcc(*'FMP4')    \n",
    "video_tracked = cv2.VideoWriter('video_tracked8.mp4', fourcc, 25.0, dim)\n",
    "for frame in frames_tracked:\n",
    "    video_tracked.write(cv2.cvtColor(np.array(frame), cv2.COLOR_RGB2BGR))\n",
    "video_tracked.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Play saved video\n",
    "cap = cv2.VideoCapture('C:/Users/Mosa-T/Desktop/content/video_tracked7.mp4')\n",
    "   \n",
    "# Check if camera opened successfully\n",
    "if (cap.isOpened()== False): \n",
    "    print(\"Error opening video  file\")\n",
    "\n",
    "#Read until video is completed\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:\n",
    "        cv2.imshow('Frame', frame)\n",
    "    else: \n",
    "        break\n",
    "        \n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "        break\n",
    "#When everything done, release \n",
    "# the video capture object\n",
    "cap.release()\n",
    "   \n",
    "# Closes all the frames\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real-Time detection of stored video with email sending "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Downloaded video fire detection - display rather than storing\n",
    "video = mmcv.VideoReader('C:/Users/Mosa-T/Desktop/content/workspace/data/test.record/video1.mp4')\n",
    "#video = mmcv.VideoReader(0)\n",
    "\n",
    "#frames = [Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)) for frame in video]\n",
    "frames = [(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)) for frame in video]\n",
    "frames_tracked = []\n",
    "mailed_flag = False\n",
    "for i, frame in enumerate(frames):\n",
    "    print('\\rTracking frames: '.format(i + 1), end='')\n",
    "    frame_draw,mailed_flag = framePred_email(frame,mailed_flag)\n",
    "    key=cv2.waitKey(1)\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    #frames_tracked.append(frame_draw)\n",
    "    cv2.imshow('detection fire',cv2.cvtColor(np.array(frame_draw), cv2.COLOR_RGB2BGR))\n",
    "print('\\nDone') \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempts at speeding up procceses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multithreading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trying multithreading for real-time \n",
    "class VideoStreamWidget(object):\n",
    "    def __init__(self, src=0):\n",
    "        self.capture = cv2.VideoCapture(src)\n",
    "        # Start the thread to read frames from the video stream\n",
    "        self.thread = Thread(target=self.update, args=())\n",
    "        self.thread.daemon = True\n",
    "        self.thread.start()\n",
    "\n",
    "    def update(self):\n",
    "        # Read the next frame from the stream in a different thread\n",
    "        while True:\n",
    "            if self.capture.isOpened():\n",
    "                (self.status, self.frame) = self.capture.read()\n",
    "            time.sleep(.01)\n",
    "\n",
    "    def show_frame(self):\n",
    "        # Display frames in main program\n",
    "        self.frame=framePred(self.frame)\n",
    "        cv2.imshow('frame', self.frame)\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord('q'):\n",
    "            self.capture.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            exit(1)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    video_stream_widget = VideoStreamWidget()\n",
    "    while True:\n",
    "        try:\n",
    "            video_stream_widget.show_frame()\n",
    "        except AttributeError:\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiprocessing - Sadly windows support for multiprocessing is very messy and buggy so we did not go through with fixing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import time\n",
    "import subprocess as sp\n",
    "#import multiprocessing as mp\n",
    "#mp = mp.set_start_method('fork')\n",
    "import multiprocess as mp\n",
    "from os import remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_frame_details(file_name):\n",
    "    cv2video = cv.VideoCapture(file_name)\n",
    "    height = cv2video.get(cv.CAP_PROP_FRAME_HEIGHT)\n",
    "    width  = cv2video.get(cv.CAP_PROP_FRAME_WIDTH) \n",
    "    framecount = cv2video.get(cv.CAP_PROP_FRAME_COUNT ) \n",
    "    return width,height,framecount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_output_files(num_processes):\n",
    "    # Create a list of output files and store the file names in a txt file\n",
    "    list_of_output_files = [\"output_{}.mp4\".format(i) for i in range(num_processes)]\n",
    "    with open(\"list_of_output_files.txt\", \"w\") as f:\n",
    "        for t in list_of_output_files:\n",
    "            f.write(\"file {} \\n\".format(t))\n",
    "\n",
    "    # use ffmpeg to combine the video output files\n",
    "    ffmpeg_cmd = \"ffmpeg -y -loglevel error -f concat -safe 0 -i list_of_output_files.txt -vcodec copy \" + output_file_name\n",
    "    sp.Popen(ffmpeg_cmd, shell=True).wait()\n",
    "\n",
    "    # Remove the temperory output files\n",
    "    for f in list_of_output_files:\n",
    "        remove(f)\n",
    "    remove(\"list_of_output_files.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video():\n",
    "    # Read video file\n",
    "    cap = cv.VideoCapture(file_name)\n",
    "\n",
    "    # get height, width and frame count of the video\n",
    "    width, height = (\n",
    "            int(cap.get(cv.CAP_PROP_FRAME_WIDTH)),\n",
    "            int(cap.get(cv.CAP_PROP_FRAME_HEIGHT))\n",
    "        )\n",
    "    fps = int(cap.get(cv.CAP_PROP_FPS))\n",
    "\n",
    "    # Define the codec and create VideoWriter object\n",
    "    fourcc = cv.VideoWriter_fourcc(*'FMP4')\n",
    "    out = cv.VideoWriter()\n",
    "    output_file_name = \"output_single.mp4\"\n",
    "    out.open(output_file_name, fourcc, fps, (width, height), True)\n",
    "\n",
    "    try:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            #print(ret)\n",
    "            if not ret:\n",
    "                break\n",
    "            im = frame\n",
    "            # Perform detection of frame\n",
    "            im = framePred(im)\n",
    "            #print(ret)\n",
    "            # write the frame\n",
    "            out.write(im)\n",
    "    except:\n",
    "        # Release resources\n",
    "        cap.release()\n",
    "        out.release()\n",
    "        \n",
    "\n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_process():\n",
    "    print(\"Video processing using single process...\")\n",
    "    start_time = time.time()\n",
    "    process_video()\n",
    "    end_time = time.time()\n",
    "    total_processing_time = end_time - start_time\n",
    "    print(\"Time taken: {}\".format(total_processing_time))\n",
    "    print(\"FPS : {}\".format(frame_count/total_processing_time))\n",
    "    \n",
    "file_name = \"C:/Users/Mosa-T/Desktop/content/input.mp4\"\n",
    "output_file_name = \"output_single.mp4\"\n",
    "width, height, frame_count = get_video_frame_details(file_name)\n",
    "print(\"Video frame count = {}\".format(frame_count))\n",
    "print(\"Width = {}, Height = {}\".format(width, height))\n",
    "single_process()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiprocess - waiting on update fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video_multiprocessing(group_number):\n",
    "    # Read video file\n",
    "    import cv2 as cv\n",
    "    file_name = \"input.mp4\"\n",
    "    output_file_name = \"output.mp4\"\n",
    "    width, height, frame_count = get_video_frame_details(file_name)\n",
    "    print(\"Video frame count = {}\".format(frame_count))\n",
    "    print(\"Width = {}, Height = {}\".format(width, height))\n",
    "    num_processes = mp.cpu_count()\n",
    "    print(\"Number of CPU: \" + str(num_processes))\n",
    "    frame_jump_unit =  frame_count// num_processes\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    cap = cv.VideoCapture(file_name)\n",
    "    cap.set(cv.CAP_PROP_POS_FRAMES, frame_jump_unit * group_number)\n",
    "    # get height, width and frame count of the video\n",
    "    width, height = (\n",
    "            int(cap.get(cv.CAP_PROP_FRAME_WIDTH)),\n",
    "            int(cap.get(cv.CAP_PROP_FRAME_HEIGHT))\n",
    "        )\n",
    "    no_of_frames = int(cap.get(cv.CAP_PROP_FRAME_COUNT))\n",
    "    fps = int(cap.get(cv.CAP_PROP_FPS))\n",
    "    proc_frames = 0\n",
    "    # Define the codec and create VideoWriter object\n",
    "    fourcc = cv.VideoWriter_fourcc(*'FMP4')\n",
    "    out = cv.VideoWriter()\n",
    "    output_file_name = \"output_multi.mp4\"\n",
    "    out.open(\"output_{}.mp4\".format(group_number), fourcc, fps, (width, height), True)\n",
    "    try:\n",
    "        while proc_frames < frame_jump_unit:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            im = frame\n",
    "            # Perform face detection on each frame\n",
    "            im = framePred(im).copy()\n",
    "            # Loop through list (if empty this will be skipped) and overlay green bboxes\n",
    "            # write the frame\n",
    "            out.write(im)\n",
    "            proc_frames += 1\n",
    "    except:\n",
    "        # Release resources\n",
    "        cap.release()\n",
    "        out.release()\n",
    "\n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_process():\n",
    "    num_processes = mp.cpu_count()\n",
    "    print(\"Video processing using {} processes...\".format(num_processes))\n",
    "    start_time = time.time()\n",
    "    import cv2 as cv\n",
    "    file_name = \"input.mp4\"\n",
    "    output_file_name = \"output.mp4\"\n",
    "    width, height, frame_count = get_video_frame_details(file_name)\n",
    "    print(\"Video frame count = {}\".format(frame_count))\n",
    "    print(\"Width = {}, Height = {}\".format(width, height))\n",
    "    num_processes = mp.cpu_count()\n",
    "    print(\"Number of CPU: \" + str(num_processes))\n",
    "    frame_jump_unit =  frame_count// num_processes\n",
    "\n",
    "    # Paralle the execution of a function across multiple input values\n",
    "    p = mp.Pool(num_processes)\n",
    "    print(num_processes)\n",
    "    p.map(process_video_multiprocessing, range(num_processes))\n",
    "    print('b')\n",
    "    combine_output_files(num_processes)\n",
    "    print('c')\n",
    "    end_time = time.time()\n",
    "   \n",
    "    total_processing_time = end_time - start_time\n",
    "    print(\"Time taken: {}\".format(total_processing_time))\n",
    "    print(\"FPS : {}\".format(frame_count/total_processing_time))\n",
    "\n",
    "#file_name = \"input.mp4\"\n",
    "#output_file_name = \"output.mp4\"\n",
    "#width, height, frame_count = get_video_frame_details(file_name)\n",
    "#print(\"Video frame count = {}\".format(frame_count))\n",
    "#print(\"Width = {}, Height = {}\".format(width, height))\n",
    "#num_processes = mp.cpu_count()\n",
    "#print(\"Number of CPU: \" + str(num_processes))\n",
    "#frame_jump_unit =  frame_count// num_processes\n",
    "#multi_process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    file_name = \"input.mp4\"\n",
    "    output_file_name = \"output.mp4\"\n",
    "    width, height, frame_count = get_video_frame_details(file_name)\n",
    "    print(\"Video frame count = {}\".format(frame_count))\n",
    "    print(\"Width = {}, Height = {}\".format(width, height))\n",
    "    num_processes = mp.cpu_count()\n",
    "    print(\"Number of CPU: \" + str(num_processes))\n",
    "    frame_jump_unit =  frame_count// num_processes\n",
    "    # Paralle the execution of a function across multiple input values\n",
    "    p = mp.Pool(num_processes)\n",
    "    print(num_processes)\n",
    "    p.map(process_video_multiprocessing, range(num_processes))\n",
    "    print('b')\n",
    "    combine_output_files(num_processes)\n",
    "    print('c')\n",
    "    end_time = time.time()\n",
    "   \n",
    "    total_processing_time = end_time - start_time\n",
    "    print(\"Time taken: {}\".format(total_processing_time))\n",
    "    print(\"FPS : {}\".format(frame_count/total_processing_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helpful code - recording, playbacks and delay videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#record and playback for webcam.\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def rec():\n",
    "    # record a video\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    # Define the codec and create VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'FMP4')\n",
    "    out = cv2.VideoWriter('output.mp4',fourcc, 30.0, (640,480))\n",
    "\n",
    "    while(cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        if ret==True:\n",
    "            out.write(frame)\n",
    "            cv2.imshow('frame',frame)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    # Release everything if job is finished\n",
    "    cap.release()\n",
    "    out.release()\n",
    "\n",
    "def playback():\n",
    "    # play a video\n",
    "    cap = cv2.VideoCapture('output.mp4')\n",
    "\n",
    "    while(cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            cv2.imshow('frame',frame)\n",
    "        else:\n",
    "            break\n",
    "        if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "# create empty window to process input\n",
    "\n",
    "cv2.namedWindow('frame')\n",
    "# main loop\n",
    "while True:\n",
    "    key = cv2.waitKey(10) \n",
    "    if key == ord('r'):\n",
    "        rec()\n",
    "    elif key == ord('p'):\n",
    "        playback()\n",
    "    elif key == ord('x'):\n",
    "        # end main loop\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#webcam with delay\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "print(cap.get(3))\n",
    "print(cap.get(4))\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "DELAY_SECONDS = 5\n",
    "frames = []\n",
    "\n",
    "DELAY_SECONDS = 5\n",
    "\n",
    "while True:\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    frame = framePred(frame)\n",
    "    frames.append(frame)\n",
    "    if time.time() - start_time > DELAY_SECONDS:\n",
    "        cv2.imshow(\"frame\", frames.pop(0))\n",
    "\n",
    "    key = cv2.waitKey(60)\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows() \n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DL_project_v2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
